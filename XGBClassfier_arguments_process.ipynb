{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "============================================\n",
    "\n",
    "---------------  claude 調參過程-- ----------\n",
    "\n",
    "============================================\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                            precision_recall_curve, precision_score,recall_score,f1_score,\n",
    "                            mean_squared_error,mean_absolute_error)\n",
    "import pyvizml\n",
    "from pyvizml import ClfMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "plt.rcParams['font.family'] = 'Heiti TC' #顯示中文字(Mac OS)\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "class XGBoostHawkeyeModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.optimal_threshold = 0.5\n",
    "        self.threshold_metrics = {}\n",
    "\n",
    "    # ======================\n",
    "    # 1. 數據預處理\n",
    "    # ======================\n",
    "    def preprocess_data(self, df, target_col):\n",
    "        processed_df = df.copy()\n",
    "        label_encoders = {}\n",
    "        categorical_cols = processed_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "        for col in categorical_cols: # 在變數中\n",
    "            if col != target_col:    # 若不是目標變數\n",
    "                le = LabelEncoder()  \n",
    "                processed_df[col] = le.fit_transform(processed_df[col].astype(str))\n",
    "                label_encoders[col] = le\n",
    "\n",
    "        return processed_df, label_encoders\n",
    "\n",
    "    # ======================\n",
    "    # 2. scale_pos_weight baseline 測試\n",
    "    # ======================\n",
    "    def find_best_weight(self, X_train, y_train, X_val, y_val):\n",
    "        pos_count = (y_train == 1).sum()\n",
    "        neg_count = (y_train == 0).sum()\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "\n",
    "        print(f\"\\n正樣本數: {pos_count}, 負樣本數: {neg_count}, 建議初始 scale_pos_weight = {scale_pos_weight:.2f}\")\n",
    "\n",
    "        test_weights = [1, scale_pos_weight*0.5, scale_pos_weight, scale_pos_weight*1.5]\n",
    "        best_auc, best_weight = 0, scale_pos_weight\n",
    "\n",
    "        for w in test_weights:\n",
    "            temp_model = xgb.XGBClassifier(\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"auc\",\n",
    "                scale_pos_weight=w,\n",
    "                #use_label_encoder=False,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            temp_model.fit(X_train, y_train)\n",
    "            y_pred_prob = temp_model.predict_proba(X_val)[:, 1]\n",
    "            auc = roc_auc_score(y_val, y_pred_prob)\n",
    "            print(f\"scale_pos_weight={w:.2f}, AUC={auc:.4f}\")\n",
    "\n",
    "            if auc > best_auc:\n",
    "                best_auc, best_weight = auc, w\n",
    "\n",
    "        print(f\"最佳 scale_pos_weight = {best_weight:.2f}, AUC={best_auc:.4f}\")\n",
    "        return best_weight\n",
    "\n",
    "    # ======================\n",
    "    # 3. 閾值優化\n",
    "    # ======================\n",
    "    def find_optimal_threshold(self, y_true, y_prob, metric = \"f1\"):\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "        if metric == \"f1\":\n",
    "            optimal_idx = np.argmax(f1_scores)\n",
    "        elif metric == \"precision\":\n",
    "            optimal_idx = np.argmax(precision)\n",
    "        elif metric == \"recall\":\n",
    "            optimal_idx = np.argmax(recall)\n",
    "\n",
    "        self.optimal_threshold = thresholds[optimal_idx]\n",
    "        self.threshold_metrics = {\n",
    "            \"optimal_threshold\": self.optimal_threshold,\n",
    "            \"precision\": precision[optimal_idx],\n",
    "            \"recall\": recall[optimal_idx],\n",
    "            \"f1\": f1_scores[optimal_idx],\n",
    "        }\n",
    "\n",
    "        print(\"\\n=== 最佳閾值分析 ===\")\n",
    "        print(f\"最佳閾值: {self.optimal_threshold:.4f}\")\n",
    "        print(f\"Precision: {precision[optimal_idx]:.4f}\")\n",
    "        print(f\"Recall: {recall[optimal_idx]:.4f}\")\n",
    "        print(f\"F1: {f1_scores[optimal_idx]:.4f}\")\n",
    "\n",
    "        return self.optimal_threshold\n",
    "\n",
    "    # ======================\n",
    "    # 4. 超參數調優\n",
    "    # ======================\n",
    "    def tune_hyperparameters(self, X_train, y_train, best_weight = None ,search_type=\"grid\", cv=3, n_iter=10):\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [100, 200, 500],\n",
    "            \"max_depth\": [3, 5, 7],\n",
    "            \"learning_rate\": np.linspace(0.01, 0.2, 3),  # 減少數量\n",
    "            \"subsample\": [0.6, 0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"reg_alpha\": [0, 0.1, 1],\n",
    "            \"reg_lambda\": [0.1, 1, 10],\n",
    "        }\n",
    "\n",
    "        base_model = xgb.XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"auc\",\n",
    "            scale_pos_weight = best_weight if best_weight else 1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        if search_type == \"grid\":\n",
    "            searcher = GridSearchCV(base_model, param_grid, scoring=\"roc_auc\", cv=cv, verbose=1, n_jobs=-1)\n",
    "        else:\n",
    "            searcher = RandomizedSearchCV(base_model, param_grid, n_iter=n_iter, scoring=\"roc_auc\", cv=cv, verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "        searcher.fit(X_train, y_train)\n",
    "\n",
    "        print(\"\\n=== 超參數調優結果 ===\")\n",
    "        print(\"最佳參數:\", searcher.best_params_,'\\n')\n",
    "        print(\"最佳分數 (AUC):\", searcher.best_score_)\n",
    "\n",
    "        self.model = searcher.best_estimator_\n",
    "        return self.model\n",
    "\n",
    "    # ======================\n",
    "    # 5. 模型訓練\n",
    "    # ======================\n",
    "    def train(self, X_train, y_train, best_weight=None):\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"scale_pos_weight\": best_weight if best_weight else 1,\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "        self.model = xgb.XGBClassifier(**params)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    # ======================\n",
    "    # 6. 評估\n",
    "    # ======================\n",
    "    def evaluate(self, X_test, y_test, use_optimal_threshold=True):\n",
    "        y_prob = self.model.predict_proba(X_test)[:, 1]\n",
    "        threshold = self.optimal_threshold if use_optimal_threshold else 0.5\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "        print(\"\\n=== 模型評估 ===\")\n",
    "        print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "        print(\"F1:\", f1_score(y_test, y_pred))\n",
    "        print(\"\\n分類報告:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"混淆矩陣\")\n",
    "        plt.show()\n",
    "\n",
    "        return {\"auc\": roc_auc_score(y_test, y_prob), \"f1\": f1_score(y_test, y_pred)}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
