{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46df46-0b6f-46ce-96cb-aef201d2e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 設定中文字體\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "class XGBoostHawkeyeModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.performance_history = []\n",
    "        \n",
    "    def generate_sample_data(self, n_samples=10000):\n",
    "        \"\"\"生成模擬的台灣金融業鷹眼模型數據\"\"\"\n",
    "        print(\"正在生成模擬數據...\")\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # 客戶基本信息\n",
    "        age = np.random.normal(40, 12, n_samples)\n",
    "        income = np.random.lognormal(10.5, 0.8, n_samples)  # 年收入\n",
    "        employment_years = np.random.exponential(8, n_samples)\n",
    "        \n",
    "        # 信用歷史\n",
    "        credit_score = np.random.normal(650, 80, n_samples)\n",
    "        credit_history_length = np.random.exponential(5, n_samples)\n",
    "        num_credit_cards = np.random.poisson(3, n_samples)\n",
    "        \n",
    "        # 財務行為\n",
    "        monthly_spending = income * np.random.uniform(0.3, 0.8, n_samples) / 12\n",
    "        savings_ratio = np.random.beta(2, 5, n_samples)\n",
    "        debt_to_income = np.random.beta(2, 8, n_samples)\n",
    "        \n",
    "        # 銀行往來紀錄\n",
    "        num_bank_products = np.random.poisson(2, n_samples)\n",
    "        avg_account_balance = income * np.random.uniform(0.1, 2, n_samples)\n",
    "        transaction_frequency = np.random.poisson(50, n_samples)\n",
    "        \n",
    "        # 行業特定風險因子\n",
    "        industry_risk = np.random.choice([0, 1, 2], n_samples, p=[0.6, 0.3, 0.1])  # 0:低風險, 1:中風險, 2:高風險\n",
    "        region_risk = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])  # 0:低風險地區, 1:高風險地區\n",
    "        \n",
    "        # 最近行為異常指標\n",
    "        recent_large_transactions = np.random.poisson(1, n_samples)\n",
    "        unusual_spending_pattern = np.random.binomial(1, 0.1, n_samples)\n",
    "        late_payments_6m = np.random.poisson(0.5, n_samples)\n",
    "        \n",
    "        # 創建目標變數（詐騙/違約風險）\n",
    "        # 基於各種因素計算風險分數\n",
    "        risk_score = (\n",
    "            -0.02 * (age - 40) +  # 年齡因子\n",
    "            -0.0001 * (income - 500000) +  # 收入因子\n",
    "            -0.01 * (credit_score - 650) +  # 信用分數因子\n",
    "            0.5 * debt_to_income +  # 負債比因子\n",
    "            0.3 * industry_risk +  # 行業風險因子\n",
    "            0.2 * region_risk +  # 地區風險因子\n",
    "            0.4 * unusual_spending_pattern +  # 異常消費模式\n",
    "            0.1 * late_payments_6m +  # 遲繳紀錄\n",
    "            np.random.normal(0, 0.3, n_samples)  # 隨機噪音\n",
    "        )\n",
    "        \n",
    "        # 轉換為二元分類（約5%為高風險）\n",
    "        risk_threshold = np.percentile(risk_score, 95)\n",
    "        is_high_risk = (risk_score > risk_threshold).astype(int)\n",
    "        \n",
    "        # 建立DataFrame\n",
    "        data = pd.DataFrame({\n",
    "            'age': np.clip(age, 18, 80),\n",
    "            'income': np.clip(income, 200000, 5000000),\n",
    "            'employment_years': np.clip(employment_years, 0, 40),\n",
    "            'credit_score': np.clip(credit_score, 300, 850),\n",
    "            'credit_history_length': np.clip(credit_history_length, 0, 30),\n",
    "            'num_credit_cards': np.clip(num_credit_cards, 0, 10),\n",
    "            'monthly_spending': monthly_spending,\n",
    "            'savings_ratio': np.clip(savings_ratio, 0, 1),\n",
    "            'debt_to_income': np.clip(debt_to_income, 0, 2),\n",
    "            'num_bank_products': np.clip(num_bank_products, 0, 8),\n",
    "            'avg_account_balance': avg_account_balance,\n",
    "            'transaction_frequency': transaction_frequency,\n",
    "            'industry_risk': industry_risk,\n",
    "            'region_risk': region_risk,\n",
    "            'recent_large_transactions': recent_large_transactions,\n",
    "            'unusual_spending_pattern': unusual_spending_pattern,\n",
    "            'late_payments_6m': late_payments_6m,\n",
    "            'is_high_risk': is_high_risk\n",
    "        })\n",
    "        \n",
    "        print(f\"數據生成完成！\")\n",
    "        print(f\"總樣本數: {len(data)}\")\n",
    "        print(f\"高風險樣本數: {sum(is_high_risk)} ({sum(is_high_risk)/len(data)*100:.2f}%)\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def prepare_data(self, data):\n",
    "        \"\"\"準備訓練數據\"\"\"\n",
    "        print(\"正在準備數據...\")\n",
    "        \n",
    "        # 分離特徵和目標變數\n",
    "        X = data.drop('is_high_risk', axis=1)\n",
    "        y = data['is_high_risk']\n",
    "        \n",
    "        # 儲存特徵名稱\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        # 分割訓練集和測試集\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # 標準化數值特徵\n",
    "        numerical_features = X.select_dtypes(include=[np.number]).columns\n",
    "        X_train_scaled = X_train.copy()\n",
    "        X_test_scaled = X_test.copy()\n",
    "        \n",
    "        X_train_scaled[numerical_features] = self.scaler.fit_transform(X_train[numerical_features])\n",
    "        X_test_scaled[numerical_features] = self.scaler.transform(X_test[numerical_features])\n",
    "        \n",
    "        print(f\"訓練集大小: {X_train_scaled.shape}\")\n",
    "        print(f\"測試集大小: {X_test_scaled.shape}\")\n",
    "        print(f\"類別分布 - 訓練集: {Counter(y_train)}\")\n",
    "        print(f\"類別分布 - 測試集: {Counter(y_test)}\")\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    \n",
    "    def calculate_scale_pos_weight(self, y_train):\n",
    "        \"\"\"計算scale_pos_weight參數\"\"\"\n",
    "        neg_count = sum(y_train == 0)\n",
    "        pos_count = sum(y_train == 1)\n",
    "        scale_pos_weight = neg_count / pos_count\n",
    "        print(f\"負樣本數: {neg_count}, 正樣本數: {pos_count}\")\n",
    "        print(f\"建議的 scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "        return scale_pos_weight\n",
    "    \n",
    "    def train_baseline_model(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"訓練基線模型\"\"\"\n",
    "        print(\"\\n=== 階段1: 基線模型 ===\")\n",
    "        \n",
    "        # 基本參數\n",
    "        baseline_params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        model = xgb.XGBClassifier(**baseline_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 評估性能\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "        test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, train_pred_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "        \n",
    "        performance = {\n",
    "            'stage': '基線模型',\n",
    "            'train_auc': train_auc,\n",
    "            'test_auc': test_auc,\n",
    "            'parameters': baseline_params\n",
    "        }\n",
    "        self.performance_history.append(performance)\n",
    "        \n",
    "        print(f\"基線模型 - 訓練集 AUC: {train_auc:.4f}\")\n",
    "        print(f\"基線模型 - 測試集 AUC: {test_auc:.4f}\")\n",
    "        \n",
    "        return model, performance\n",
    "    \n",
    "    def tune_core_parameters(self, X_train, X_test, y_train, y_test, scale_pos_weight):\n",
    "        \"\"\"調整核心參數：scale_pos_weight, min_child_weight, gamma\"\"\"\n",
    "        print(\"\\n=== 階段2: 調整核心參數 ===\")\n",
    "        \n",
    "        # 參數網格\n",
    "        param_grid = {\n",
    "            'scale_pos_weight': [scale_pos_weight * 0.8, scale_pos_weight, scale_pos_weight * 1.2],\n",
    "            'min_child_weight': [1, 3, 5],\n",
    "            'gamma': [0, 0.1, 0.2]\n",
    "        }\n",
    "        \n",
    "        base_params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # 網格搜索\n",
    "        xgb_model = xgb.XGBClassifier(**base_params)\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model, param_grid, \n",
    "            cv=5, scoring='roc_auc', n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"正在進行網格搜索...\")\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # 評估性能\n",
    "        train_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "        test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, train_pred_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "        \n",
    "        performance = {\n",
    "            'stage': '核心參數調整',\n",
    "            'train_auc': train_auc,\n",
    "            'test_auc': test_auc,\n",
    "            'parameters': {**base_params, **best_params}\n",
    "        }\n",
    "        self.performance_history.append(performance)\n",
    "        \n",
    "        print(f\"最佳核心參數: {best_params}\")\n",
    "        print(f\"核心參數調整後 - 訓練集 AUC: {train_auc:.4f}\")\n",
    "        print(f\"核心參數調整後 - 測試集 AUC: {test_auc:.4f}\")\n",
    "        \n",
    "        return best_model, performance\n",
    "    \n",
    "    def tune_structure_parameters(self, X_train, X_test, y_train, y_test, core_params):\n",
    "        \"\"\"調整結構參數：max_depth, learning_rate, n_estimators\"\"\"\n",
    "        print(\"\\n=== 階段3: 調整結構參數 ===\")\n",
    "        \n",
    "        # 參數網格\n",
    "        param_grid = {\n",
    "            'max_depth': [4, 6, 8],\n",
    "            'learning_rate': [0.05, 0.1, 0.2],\n",
    "            'n_estimators': [100, 200, 300]\n",
    "        }\n",
    "        \n",
    "        # 網格搜索\n",
    "        xgb_model = xgb.XGBClassifier(**core_params)\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model, param_grid, \n",
    "            cv=5, scoring='roc_auc', n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"正在進行結構參數網格搜索...\")\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # 評估性能\n",
    "        train_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "        test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, train_pred_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "        \n",
    "        final_params = {**core_params, **best_params}\n",
    "        performance = {\n",
    "            'stage': '結構參數調整',\n",
    "            'train_auc': train_auc,\n",
    "            'test_auc': test_auc,\n",
    "            'parameters': final_params\n",
    "        }\n",
    "        self.performance_history.append(performance)\n",
    "        \n",
    "        print(f\"最佳結構參數: {best_params}\")\n",
    "        print(f\"最終模型 - 訓練集 AUC: {train_auc:.4f}\")\n",
    "        print(f\"最終模型 - 測試集 AUC: {test_auc:.4f}\")\n",
    "        \n",
    "        self.model = best_model\n",
    "        return best_model, performance\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"詳細評估最終模型\"\"\"\n",
    "        print(\"\\n=== 最終模型評估 ===\")\n",
    "        \n",
    "        # 預測\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # 分類報告\n",
    "        print(\"\\n分類報告:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # AUC分數\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"\\nROC AUC Score: {auc_score:.4f}\")\n",
    "        \n",
    "        # 混淆矩陣\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"\\n混淆矩陣:\")\n",
    "        print(cm)\n",
    "        \n",
    "        return {\n",
    "            'auc': auc_score,\n",
    "            'classification_report': classification_report(y_test, y_pred, output_dict=True),\n",
    "            'confusion_matrix': cm,\n",
    "            'predictions': y_pred,\n",
    "            'prediction_probabilities': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    def plot_performance_comparison(self):\n",
    "        \"\"\"繪製性能比較圖\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        stages = [p['stage'] for p in self.performance_history]\n",
    "        train_aucs = [p['train_auc'] for p in self.performance_history]\n",
    "        test_aucs = [p['test_auc'] for p in self.performance_history]\n",
    "        \n",
    "        x = range(len(stages))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar([i - width/2 for i in x], train_aucs, width, label='訓練集 AUC', alpha=0.8)\n",
    "        plt.bar([i + width/2 for i in x], test_aucs, width, label='測試集 AUC', alpha=0.8)\n",
    "        plt.xlabel('調參階段')\n",
    "        plt.ylabel('AUC Score')\n",
    "        plt.title('模型性能提升過程')\n",
    "        plt.xticks(x, stages, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # AUC提升量\n",
    "        plt.subplot(1, 2, 2)\n",
    "        test_auc_improvements = [0] + [test_aucs[i] - test_aucs[i-1] for i in range(1, len(test_aucs))]\n",
    "        colors = ['green' if imp >= 0 else 'red' for imp in test_auc_improvements]\n",
    "        plt.bar(x, test_auc_improvements, color=colors, alpha=0.7)\n",
    "        plt.xlabel('調參階段')\n",
    "        plt.ylabel('AUC 改善量')\n",
    "        plt.title('各階段AUC提升情況')\n",
    "        plt.xticks(x, stages, rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 印出詳細的性能改善報告\n",
    "        print(\"\\n=== 性能改善報告 ===\")\n",
    "        for i, perf in enumerate(self.performance_history):\n",
    "            if i == 0:\n",
    "                print(f\"{perf['stage']}: 測試集 AUC = {perf['test_auc']:.4f} (基準)\")\n",
    "            else:\n",
    "                improvement = perf['test_auc'] - self.performance_history[i-1]['test_auc']\n",
    "                print(f\"{perf['stage']}: 測試集 AUC = {perf['test_auc']:.4f} (提升 {improvement:+.4f})\")\n",
    "        \n",
    "        total_improvement = self.performance_history[-1]['test_auc'] - self.performance_history[0]['test_auc']\n",
    "        print(f\"\\n總體改善: {total_improvement:+.4f} ({total_improvement/self.performance_history[0]['test_auc']*100:+.2f}%)\")\n",
    "    \n",
    "    def plot_feature_importance(self):\n",
    "        \"\"\"繪製特徵重要性\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"請先訓練模型\")\n",
    "            return\n",
    "        \n",
    "        # 獲取特徵重要性\n",
    "        importance = self.model.feature_importances_\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.barplot(data=feature_importance.head(15), y='feature', x='importance')\n",
    "        plt.title('特徵重要性排序 (Top 15)')\n",
    "        plt.xlabel('重要性分數')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"特徵重要性排序:\")\n",
    "        for i, row in feature_importance.head(10).iterrows():\n",
    "            print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# 主要執行程序\n",
    "def main():\n",
    "    print(\"台灣金融業鷹眼模型 - XGBoost調參示範\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 初始化模型\n",
    "    hawkeye_model = XGBoostHawkeyeModel()\n",
    "    \n",
    "    # 1. 生成模擬數據\n",
    "    data = hawkeye_model.generate_sample_data(n_samples=10000)\n",
    "    \n",
    "    # 2. 準備數據\n",
    "    X_train, X_test, y_train, y_test = hawkeye_model.prepare_data(data)\n",
    "    \n",
    "    # 3. 計算scale_pos_weight\n",
    "    scale_pos_weight = hawkeye_model.calculate_scale_pos_weight(y_train)\n",
    "    \n",
    "    # 4. 階段性調參\n",
    "    \n",
    "    # 階段1: 基線模型\n",
    "    baseline_model, baseline_perf = hawkeye_model.train_baseline_model(\n",
    "        X_train, X_test, y_train, y_test\n",
    "    )\n",
    "    \n",
    "    # 階段2: 調整核心參數\n",
    "    core_model, core_perf = hawkeye_model.tune_core_parameters(\n",
    "        X_train, X_test, y_train, y_test, scale_pos_weight\n",
    "    )\n",
    "    \n",
    "    # 階段3: 調整結構參數\n",
    "    final_model, final_perf = hawkeye_model.tune_structure_parameters(\n",
    "        X_train, X_test, y_train, y_test, core_perf['parameters']\n",
    "    )\n",
    "    \n",
    "    # 5. 模型評估\n",
    "    evaluation_results = hawkeye_model.evaluate_model(X_test, y_test)\n",
    "    \n",
    "    # 6. 視覺化結果\n",
    "    hawkeye_model.plot_performance_comparison()\n",
    "    hawkeye_model.plot_feature_importance()\n",
    "    \n",
    "    # 7. 輸出最終結果摘要\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"最終結果摘要\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"最終模型 AUC: {evaluation_results['auc']:.4f}\")\n",
    "    print(f\"模型總體提升: {final_perf['test_auc'] - baseline_perf['test_auc']:+.4f}\")\n",
    "    \n",
    "    final_params = final_perf['parameters']\n",
    "    print(f\"\\n最佳參數組合:\")\n",
    "    for param, value in final_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
