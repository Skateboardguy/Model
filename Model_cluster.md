| 模型                      | 本質                    | 損失函數                                  | 使用情境         | 特徵處理                            | 解釋方式                                |       |                     |
| ----------------------- | --------------------- | ------------------------------------- | ------------ | ------------------------------- | ----------------------------------- | ----- | ------------------- |
| **OLS (多因子迴歸)**         | 線性迴歸                  | $\text{SSE} = \sum (y - \hat{y})^2$   | 連續型 y，少量變數   | 類別要轉 dummy，連續可直接用               | 係數 + p-value 顯著性                    |       |                     |
| **Ridge (L2)**          | 線性迴歸 + 正則化            | $\text{SSE} + \lambda \sum \beta_j^2$ | 多變數、高共線性     | 必須標準化                           | 係數收縮，但不會變 0                         |       |                     |
| **Lasso (L1)**          | 線性迴歸 + 正則化            | $\text{SSE} + \lambda \sum \|beta\_j|$| 高維度，需挑變數     | 必須標準化     | 自動變數篩選 (部分係數=0)     $
| **ElasticNet**          | 線性迴歸 + L1+L2             | $\text{SSE} + \alpha(\lambda\_1 \sum | \beta\_j     | + \lambda\_2 \sum \beta\_j^2) ) | 變數很多且相關性強                           | 必須標準化 | 兼顧 Ridge + Lasso 優點 |
| **Logistic Regression** | 廣義線性模型 (GLM)          | 負對數似然 (Cross-Entropy)                 | 分類任務 (y=0/1) | 類別要 dummy，連續可直接用                | 係數 → log odds 解釋；可算 OR 值            |       |                     |
| **XGBoost (回歸/分類)**     | 集成樹模型 (Boosted Trees) | 根據任務 (平方誤差 / Logloss 等)               | 複雜非線性資料      | 連續可直接用；類別需編碼 (Label/One-hot)    | 特徵重要性 (Gain/Weight/Cover)，無 p-value |       |                     |

