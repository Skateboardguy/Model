{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python 零售銀行機器學習\n",
    "\n",
    "> 機器學習模組：Scikit-Learn\n",
    "\n",
    "[郭耀仁](https://hahow.in/@tonykuoyj?tr=tonykuoyj) | yaojenkuo@ntu.edu.tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 更多面對預測任務的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 面對預測任務的模型\n",
    "\n",
    "- 正規方程。\n",
    "- 羅吉斯回歸。\n",
    "- k 最近鄰。\n",
    "- 高斯單純貝氏分類器。\n",
    "- 決策樹。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 k 最近鄰\n",
    "\n",
    "- k 最近鄰（k-Nearest Neighbors, KNN）是一種基於資料之間的相似度來決定是否為同一類別的演算方法。\n",
    "- 「歐幾里德距離 Euclidean distance」是最常用來量測資料相似度的指標，歐幾里德距離以白話文敘述其實就是直線距離。\n",
    "\n",
    "\\begin{align}\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 k 最近鄰（續）\n",
    "\n",
    "- 更為泛用的距離量測是「明可夫斯基距離 Minkowski distance」。\n",
    "- 當式子中的 $p=1$ 時就是曼哈頓距離、$p=2$ 時就是歐幾里德距離。\n",
    "\n",
    "\\begin{align}\n",
    "d(x, y) = \\left( \\sum_{i=1}^{n} \\mid x_i - y_i \\mid ^p \\right)^{\\frac{1}{p}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 k 最近鄰（續）\n",
    "\n",
    "- k 最近鄰會根據預測資料點周遭的 k 個最相似訓練資料點決定分類結果，k 可以由使用者自行決定。\n",
    "- 在二元分類的範疇下，k 會選擇一個奇數使得分類結果直接被決定。\n",
    "- k 最近鄰模型的訓練與預測在同時間發生，也就是訓練在輸入預測資料時才發生，因此屬於 Lazy learning 的機器學習方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義 k 最近鄰預測器類別\n",
    "\n",
    "```python\n",
    "class kNN:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self._n_neighbors = n_neighbors\n",
    "    def minkowski_distances(self, X_train, X_test_i, p=2):\n",
    "        distances = (np.sum((np.abs(X_test_i - X_train))**p, axis=1))**(1/p)\n",
    "        return distances\n",
    "    def fit(self, X_train, y_train):\n",
    "        self._X_train = X_train\n",
    "        self._y_train = y_train\n",
    "    def predict(self, X_test, p=2):\n",
    "        nrows = X_test.shape[0]\n",
    "        y_test = []\n",
    "        for i in range(nrows):\n",
    "            X_test_i = X_test[i, :]\n",
    "            distances = self.minkowski_distances(self._X_train, X_test_i)\n",
    "            y_train_reshape = self._y_train.reshape(-1, 1)\n",
    "            distances_reshape = distances.reshape(-1, 1)\n",
    "            distances_y_train = np.concatenate((distances_reshape, y_train_reshape), axis=1)\n",
    "            distances_y_train_argsort = distances_y_train[distances_y_train[:, 0].argsort()]\n",
    "            k_nearest_labels = distances_y_train_argsort[:self._n_neighbors, 1].astype(int)\n",
    "            labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            argmax_counts = np.argmax(counts)\n",
    "            y_test_i = labels[argmax_counts]\n",
    "            y_test.append(y_test_i)\n",
    "        return np.array(y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 高斯單純貝氏分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器\n",
    "\n",
    "- 高斯單純貝氏分類器是基於貝氏定理的分類模型。\n",
    "- 貝氏定理是在先驗機率（Prior probability）的基礎上，納入新事件的資訊來更新先驗機率，得到後驗機率（Posterior probability）的統計分法。\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x_i) = \\frac{P(x_i|y) \\times P(y)}{P(x_i)} \\\\\n",
    "\\text{posterior} = \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{evidence}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器（續）\n",
    "\n",
    "- 高斯單純貝氏分類器中的「單純」指的是在計算分類機率時，會假設資料特徵不依賴類別，兩者彼此獨立。\n",
    "- 因此實際在計算後驗機率的時候，只需要關注分子的部分。\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x_i) \\propto P(x_i|y) P(y) \\\\\n",
    "y^* = argmax_y \\, P(x_i|y) P(y) \\\\\n",
    "y^* = argmax_y \\, P(y) \\prod P(x_i|y)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器（續）\n",
    "\n",
    "當特徵為連續型變數時，可以藉由假設變數為常態分配的情況下，以樣本資料的平均數及標準差來計算機率（Likelihood），也就是 $P(x_i|y)$ 能以高斯機率密度函數計算。\n",
    "\n",
    "\\begin{align}\n",
    "P(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y^2}} exp \\left( -\\frac{(x_i - \\mu_y)^2}{2 \\sigma_y^2} \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是高斯單純貝氏分類器（續）\n",
    "\n",
    "當特徵數量很多的時候，$\\prod P(x_i|y)$ 相乘所算出的機率值會非常小，造成後驗機率趨近於 0，這時可以透過取對數函數來避免。\n",
    "\n",
    "\\begin{align}\n",
    "y^* = argmax_y \\, log \\left(P(y) \\right) + \\sum log \\left( P(x_i|y) \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義高斯單純貝氏分類器的類別\n",
    "\n",
    "```python\n",
    "class GaussianNaiveBayes:\n",
    "    def get_prior_proba(self, y_train):\n",
    "        values, counts = np.unique(y_train, return_counts=True)\n",
    "        prior_proba = dict()\n",
    "        for value, count in zip(values, counts):\n",
    "            prior_proba[value] = count / y_train.size\n",
    "        return prior_proba\n",
    "    def get_mean_var(self, X_train, y_train):\n",
    "        n_features = X_train.shape[1]\n",
    "        X_y_train = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        unique_labels = np.unique(y_train)\n",
    "        X_mean_var = dict()\n",
    "        for unique_label in unique_labels:\n",
    "            X_y_train_label = X_y_train[X_y_train[:, -1] == unique_label]\n",
    "            label_mean = np.mean(X_y_train_label[:, 0:-1], axis=0)\n",
    "            label_var = np.var(X_y_train_label[:, 0:-1], axis=0)\n",
    "            X_mean_var[unique_label] = {\n",
    "                \"mean\": label_mean,\n",
    "                \"var\": label_var\n",
    "            }\n",
    "        return X_mean_var\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def fit(self, X_train, y_train):\n",
    "        prior_proba = self.get_prior_proba(y_train)\n",
    "        mean_var = self.get_mean_var(X_train, y_train)\n",
    "        self._prior_proba = prior_proba\n",
    "        self._mean_var = mean_var\n",
    "    def get_likelihood(self, X_test_i, var, mean):\n",
    "        multiplier = 1 / np.sqrt(2 * np.pi * var)\n",
    "        numerator = (X_test_i - mean)**2\n",
    "        denominator = 2*var\n",
    "        exponenet = np.exp(- numerator / denominator)\n",
    "        likelihood = multiplier * exponenet\n",
    "        return likelihood\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def predict(self, X_test):\n",
    "        n_rows = X_test.shape[0]\n",
    "        labels = self._prior_proba.keys()\n",
    "        y_preds = []\n",
    "        for i in range(n_rows):\n",
    "            X_test_i = X_test[i, :]\n",
    "            log_posterior_probas = []\n",
    "            for label in labels:\n",
    "                label_var = self._mean_var[label][\"var\"]\n",
    "                label_mean = self._mean_var[label][\"mean\"]\n",
    "                likelihood = self.get_likelihood(X_test_i, label_var, label_mean)\n",
    "                log_likelihood = np.log(likelihood)\n",
    "                sum_log_likelihood = np.sum(log_likelihood)\n",
    "                log_prior_proba = np.log(self._prior_proba[label])\n",
    "                log_posterior_proba = log_prior_proba + sum_log_likelihood\n",
    "                log_posterior_probas.append(log_posterior_proba)\n",
    "            log_posterior_probas = np.array(log_posterior_probas)\n",
    "            y_pred = np.argmax(log_posterior_probas)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 決策樹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是決策樹\n",
    "\n",
    "- 決策樹（Decision tree）是一種利用外型像樹一樣的圖形決策模型，具有快速、可解釋性高的優點。\n",
    "- 決策樹需要從資料中尋找合適的「特徵」與「切點」來進行樹的分支，多次分支後企圖讓資料有高差異性的分類。\n",
    "- 例如決策是否要跑一場馬拉松：\n",
    "    - 氣溫是否低於 15 度？\n",
    "        - 否，不要跑。\n",
    "        - 是。\n",
    "            - 濕度是否低於 60%？\n",
    "                - 否，不要跑。\n",
    "                - 是，要跑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是決策樹（續）\n",
    "\n",
    "建立一個決策樹模型必須要考量三個要素：\n",
    "\n",
    "1. 要使用資料中的哪個變數作為特徵。\n",
    "2. 要如何決定特徵的切點。\n",
    "3. 何時要停止分支。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是決策樹（續）\n",
    "\n",
    "- 使用演算法計算資訊增益（Information Gain）、熵（Entropy）、資訊增益率（Information Gain Ratio）或吉尼不純度（Gini Impurity）來決定前述三要素。\n",
    "- 因此建構決策樹的演算法可再分為：\n",
    "    - ID3(Iterative Dichotomiser 3)\n",
    "    - C4.5\n",
    "    - C5.0\n",
    "    - CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 自行定義決策樹的類別\n",
    "\n",
    "```python\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, information_gain=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.information_gain = information_gain\n",
    "        self.value = value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "    def get_entropy(self, x):\n",
    "        epsilon = 1e-6\n",
    "        values, counts = np.unique(x, return_counts=True)\n",
    "        p = counts / counts.sum()\n",
    "        entropy = np.sum(-p * np.log2(p + epsilon)) # to avoid log2(0)\n",
    "        return(entropy)\n",
    "    def get_information_gain(self, parent_node, left_child_node, right_child_node):\n",
    "        parent_entropy = self.get_entropy(parent_node)\n",
    "        p_left = left_child_node.size / parent_node.size\n",
    "        p_right = right_child_node.size / parent_node.size\n",
    "        child_entropy = p_left*self.get_entropy(left_child_node) + p_right*self.get_entropy(right_child_node)\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def get_best_split(self, X_train, y_train):\n",
    "        best_split = dict()\n",
    "        best_information_gain = -1\n",
    "        n_rows, n_cols = X_train.shape\n",
    "        for col_idx in range(n_cols):\n",
    "            X_col_i = X_train[:, col_idx]\n",
    "            uniques = np.unique(X_col_i)\n",
    "            for threshold in uniques:\n",
    "                X_train_y_train = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "                Xy_left = X_train_y_train[X_col_i <= threshold]\n",
    "                Xy_right = X_train_y_train[X_col_i > threshold]\n",
    "                if Xy_left.shape[0] > 0 and Xy_right.shape[0] > 0:\n",
    "                    y_parent = X_train_y_train[:, -1]\n",
    "                    y_left = Xy_left[:, -1]\n",
    "                    y_right = Xy_right[:, -1]\n",
    "                    information_gain = self.get_information_gain(y_parent, y_left, y_right)\n",
    "                    if information_gain > best_information_gain:\n",
    "                        best_split = {\n",
    "                            \"column_index\": col_idx,\n",
    "                            \"threshold\": threshold,\n",
    "                            \"Xy_left\": Xy_left,\n",
    "                            \"Xy_right\": Xy_right,\n",
    "                            \"information_gain\": information_gain\n",
    "                        }\n",
    "                        best_information_gain = information_gain\n",
    "        return best_split\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def build(self, X_train, y_train, depth=0):\n",
    "        n_rows, n_cols = X_train.shape\n",
    "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(X_train, y_train)\n",
    "            if best_split[\"information_gain\"] > 0:\n",
    "                X_left = best_split[\"Xy_left\"][:, :-1]\n",
    "                y_left = best_split[\"Xy_left\"][:, -1]\n",
    "                left_node = self.build(X_left,\n",
    "                                       y_left,\n",
    "                                       depth = depth + 1)\n",
    "                X_right = best_split[\"Xy_right\"][:, :-1]\n",
    "                y_right = best_split[\"Xy_right\"][:, -1]\n",
    "                right_node = self.build(X_right,\n",
    "                                        y_right,\n",
    "                                        depth = depth + 1)\n",
    "                return Node(feature = best_split[\"column_index\"],\n",
    "                            threshold = best_split[\"threshold\"],\n",
    "                            left = left_node,\n",
    "                            right = right_node,\n",
    "                            information_gain = best_split[\"information_gain\"])\n",
    "        values, counts = np.unique(y_train, return_counts=True)\n",
    "        argmax_counts = np.argmax(counts)\n",
    "        most_common = values[argmax_counts]\n",
    "        return Node(value=most_common)\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.root = self.build(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "    def predict_X_test_i(self, X_test_i, tree):\n",
    "        if tree.value != None:\n",
    "            return tree.value\n",
    "        col_idx = tree.feature\n",
    "        feature_value = X_test_i[col_idx]\n",
    "        if feature_value <= tree.threshold:\n",
    "            return self.predict_X_test_i(X_test_i, tree.left)\n",
    "        if feature_value > tree.threshold:\n",
    "            return self.predict_X_test_i(X_test_i, tree.right)\n",
    "    def predict(self, X_test):\n",
    "        n_rows = X_test.shape[0]\n",
    "        y_test = []\n",
    "        for i in range(n_rows):\n",
    "            X_test_i = X_test[i, :]\n",
    "            y_test_i = self.predict_X_test_i(X_test_i, self.root)\n",
    "            y_test.append(y_test_i)\n",
    "        return np.array(y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 這還只是我們列出來的很小一部分\n",
    "\n",
    "- 正規方程。\n",
    "- 羅吉斯回歸。\n",
    "- k 最近鄰。\n",
    "- 高斯單純貝氏分類器。\n",
    "- 決策樹。\n",
    "- 隨機森林。\n",
    "- 梯度遞增(XGBoost)。\n",
    "- ...etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## scikit-learn to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 關於 Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 Scikit-Learn\n",
    "\n",
    "> Scikit-learn 是 Python 機器學習的第三方模組，透過它可以進行監督式以及非監督式學習，提供了模型訓練、資料預處理、模型選擇以及模型評估等功能。\n",
    "\n",
    "來源：<https://scikit-learn.org>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （沒什麼用的冷知識）Scikit-Learn 是最受歡迎的 SciKit(SciPy Toolkit)\n",
    "\n",
    "- Scikit-Learn 與 Scikit-Image 是兩個最受歡迎、維護最良善的 Scikits\n",
    "- 還有眾多其他的 Scikits\n",
    "\n",
    "來源：<https://projects.scipy.org/scikits.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 根據說明文件的範例載入\n",
    "\n",
    "多數時候我們使用 Scikit-Learn 中的特定類別或函數，因此以 `from sklearn import FUNCTION/CLASS` 載入特定類別或函數，而非 `import sklearn`\n",
    "\n",
    "來源：<https://scikit-learn.org/stable/getting_started.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn # use `from sklearn import FUNCTION/CLASS` instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 如果環境中沒有安裝 Scikit-Learn，載入時會遭遇 `ModuleNotFoundError`\n",
    "\n",
    "```\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "ModuleNotFoundError: No module named 'sklearn'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 如果遭遇 `ModuleNotFoundError` 可以在終端機使用 `pip install scikit-learn` 或者 `conda install scikit-learn` 指令安裝\n",
    "\n",
    "若要指定模組版本可以加上 `==MAJOR.MINOR.PATCH` 課程使用的模組版本為 1.0\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn==1.0\n",
    "```\n",
    "或者\n",
    "\n",
    "```bash\n",
    "conda install scikit-learn==1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 可以透過兩個屬性檢查版本號與安裝路徑\n",
    "\n",
    "- `__version__` 屬性檢查版本號。\n",
    "- `__file__` 屬性檢查安裝路徑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "/Users/kuoyaojen/miniconda3/envs/datascience/lib/python3.11/site-packages/sklearn/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)\n",
    "print(sklearn.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 為什麼選擇 Scikit-Learn\n",
    "\n",
    "- 簡潔、一致且設計良善的應用程式介面設計，只要理解基礎用法和語法，就能延伸切換到其他的演算法或模型。\n",
    "- 文件撰寫完整而豐富。\n",
    "- 維護良善。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-Learn 應用程式介面設計原則\n",
    "\n",
    "1. 一致性。\n",
    "2. 可檢查性。\n",
    "3. 不擴增新類別。\n",
    "4. 可組合性。\n",
    "5. 合理預設參數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 使用轉換器預處理資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 轉換器與預測器是 Scikit-Learn 所創造最重要的兩種類別\n",
    "\n",
    "1. **轉換器（Transformers）：用來預處理資料**。\n",
    "2. 預測器（Predictors）：用來訓練模型、生成規則 $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 轉換器的標準步驟\n",
    "\n",
    "1. 準備欲轉換的特徵矩陣 $X$ 或目標陣列 $y$\n",
    "2. 建立轉換器類別的物件。\n",
    "3. 將欲轉換的特徵矩陣 $X$ 或目標陣列 $y$ 輸入 `transformer.fit_transform()`\n",
    "4. 檢查轉換結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 轉換器 `PolynomialFeatures`\n",
    "\n",
    "生成一個指定次方數的特徵多項式矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  7. 49.]\n",
      " [ 1.  6. 36.]\n",
      " [ 1.  7. 49.]\n",
      " [ 1.  7. 49.]\n",
      " [ 1.  8. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "csv_url = \"https://raw.githubusercontent.com/datainpoint/classroom-python-for-finance-2025/refs/heads/main/ames/train.csv\"\n",
    "ames_train = pd.read_csv(csv_url) # import data\n",
    "X = ames_train[\"OverallQual\"].values.reshape(-1, 1)    # step 1\n",
    "polynomial_features = PolynomialFeatures()             # step 2\n",
    "X_transformed = polynomial_features.fit_transform(X)   # step 3\n",
    "print(X_transformed[:5])                               # step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 轉換器 `StandardScaler`\n",
    "\n",
    "生成一個經過 z-score 標準化的特徵矩陣。\n",
    "\n",
    "\\begin{equation}\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.65147924]\n",
      " [-0.07183611]\n",
      " [ 0.65147924]\n",
      " [ 0.65147924]\n",
      " [ 1.3747946 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()                     # step 2\n",
    "X_transformed = standard_scaler.fit_transform(X)       # step 3\n",
    "print(X_transformed[:5])                               # step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 兩種表示類別向量的形式\n",
    "\n",
    "- 標籤編碼(LabelEncoder)。\n",
    "- 讀熱編碼(OneHotEncoder)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 標籤編碼（Label encoder）\n",
    "\n",
    "將類別變數的獨一值用 0 到 `n_classes - 1` 的整數表示，可以使用 Scikit-Learn 中的 `LabelEncoder` 轉換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female']\n",
      "[1 0 0 0 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_url = \"https://raw.githubusercontent.com/datainpoint/classroom-python-for-finance-2025/refs/heads/main/titanic/train.csv\"\n",
    "titanic_train = pd.read_csv(csv_url)\n",
    "le = LabelEncoder()\n",
    "gender = titanic_train[\"Sex\"].values\n",
    "gender_le = le.fit_transform(gender)\n",
    "print(gender[:10])\n",
    "print(gender_le[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 讀熱編碼（OneHot encoder）\n",
    "\n",
    "將類別變數的獨一值用 0 到 `n_classes - 1` 的整數表示，可以使用 Scikit-Learn 中的 `LabelEncoder` 轉換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female']\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "oe = OneHotEncoder()\n",
    "gender = titanic_train[\"Sex\"].values\n",
    "gender_oe = oe.fit_transform(gender.reshape(-1, 1)).toarray()\n",
    "print(gender[:10])\n",
    "print(gender_oe[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 使用預測器訓練及預測資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## （複習）轉換器與預測器是 Scikit-Learn 所創造最重要的兩種類別\n",
    "\n",
    "1. 轉換器（Transformers）：用來預處理資料。\n",
    "2. **預測器（Predictors）：用來訓練模型、生成規則 $w$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器的標準步驟\n",
    "\n",
    "1. 準備欲訓練預測的特徵矩陣 $X$  與目標陣列 $y$\n",
    "2. 切割訓練與驗證資料。\n",
    "3. 建立預測器類別的物件。\n",
    "4. 將訓練特徵矩陣 $X^{train}$ 與目標陣列 $y^{train}$ 輸入 `predictor.fit()`\n",
    "5. 將驗證特徵矩陣 $X^{valid}$ 輸入 `predictor.predict()` 獲得 $\\hat{y}^{valid}$\n",
    "6. 比對 $\\hat{y}^{valid}$ 與 $y^{valid}$ 之間的差異。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器 `LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = ames_train[\"OverallQual\"].values.reshape(-1, 1)                          # step 1\n",
    "y = ames_train[\"SalePrice\"].values                                           # step 1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                    test_size=0.33, random_state=42) # step 2\n",
    "linear_regression = LinearRegression()                                       # step 3\n",
    "linear_regression.fit(X_train, y_train)                                      # step 4\n",
    "y_hat = linear_regression.predict(X_valid)                                   # step 5\n",
    "m = y_valid.size                                                             # step 6\n",
    "mean_squared_error = ((y_valid - y_hat)**2).sum()/m                          # step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器 `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "csv_url = \"https://raw.githubusercontent.com/datainpoint/classroom-python-for-finance-2025/refs/heads/main/titanic/train.csv\"\n",
    "titanic_train = pd.read_csv(csv_url)\n",
    "X = titanic_train[[\"Parch\", \"Fare\"]].values                                  # step 1\n",
    "y = titanic_train[\"Survived\"].values                                         # step 1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                            test_size=0.33, random_state=42) # step 2\n",
    "logistic_regression = LogisticRegression()                                   # step 3\n",
    "logistic_regression.fit(X_train, y_train)                                    # step 4\n",
    "y_hat = logistic_regression.predict(X_valid)                                 # step 5\n",
    "number_of_misclassification = (y_valid != y_hat).sum()                       # step 6\n",
    "print(number_of_misclassification)                                           # step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 複習：Scikit-Learn 應用程式介面設計原則\n",
    "\n",
    "- 一致性。\n",
    "    - 每個轉換器類別都有 `fit_transform()` 方法。\n",
    "    - 每個預測器類別都有 `fit()` 與 `predict()` 方法。\n",
    "- 合理預設參數。\n",
    "    - 每個轉換器、預測器都可以用預設參數建立物件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 複習：Scikit-Learn 應用程式介面設計原則（續）\n",
    "\n",
    "可檢查性：每個轉換器或預測器都有屬性讓使用者檢視轉換或預測的規則。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[6.09931507]\n",
      "[1.38252284]\n",
      "-86359.39607039432\n",
      "[43696.47641718]\n",
      "[-0.95144328]\n",
      "[[0.01009638 0.01391083]]\n"
     ]
    }
   ],
   "source": [
    "print(polynomial_features.degree)\n",
    "print(standard_scaler.mean_)\n",
    "print(standard_scaler.scale_)\n",
    "print(linear_regression.intercept_)\n",
    "print(linear_regression.coef_)\n",
    "print(logistic_regression.intercept_)\n",
    "print(logistic_regression.coef_)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Py39",
   "language": "python",
   "name": "py39clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
